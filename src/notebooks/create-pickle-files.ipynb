{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Clone MiCE repo:","metadata":{"id":"OVM8tNUcfqou"}},{"cell_type":"code","source":"!git clone --branch random_with_pos https://github.com/thanoskaravangelis/mice","metadata":{"id":"iGR43jKz0-8N","outputId":"78453323-b2de-4d87-a4db-39c196965c41","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd mice","metadata":{"id":"xBUqvIh71IMo","outputId":"f5d55a32-14a2-4ffd-e2b3-a419e9ac55d9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Conda installation","metadata":{"id":"yQfObWzHxFiP"}},{"cell_type":"code","source":"!pip install -r requirements.txt --force-reinstall","metadata":{"id":"2D8zpgbDgHTJ","outputId":"62e8156a-758b-4163-8efc-77825128021f","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m spacy download en_core_web_sm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://storage.googleapis.com/allennlp-public-models/mice-newsgroups-predictor.tar.gz\n!wget https://storage.googleapis.com/allennlp-public-models/mice-newsgroups-editor.pth\n!mkdir -p trained_predictors/newsgroups/model\n!mkdir -p results/newsgroups/editors/mice\n!mv mice-newsgroups-predictor.tar.gz trained_predictors/newsgroups/model/model.tar.gz\n!mv mice-newsgroups-editor.pth results/newsgroups/editors/mice/newsgroups_editor.pth","metadata":{"id":"Uy1OfbboghJJ","outputId":"6835cc64-6c6e-48ac-b507-919aa02593c8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://storage.googleapis.com/allennlp-public-models/mice-imdb-predictor.tar.gz\n!wget https://storage.googleapis.com/allennlp-public-models/mice-imdb-editor.pth\n!mkdir -p trained_predictors/imdb/model\n!mkdir -p results/imdb/editors/mice\n!mv mice-imdb-predictor.tar.gz trained_predictors/imdb/model/model.tar.gz\n!mv mice-imdb-editor.pth results/imdb/editors/mice/imdb_editor.pth","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load predictors","metadata":{}},{"cell_type":"code","source":"from src.utils import *","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictor = load_predictor(\"imdb\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictor_news = load_predictor(\"newsgroups\")","metadata":{"id":"N_1-LtKXgF8Z","outputId":"835f6d34-4e46-403d-a91f-43498a64e26a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Specify paths","metadata":{}},{"cell_type":"code","source":"FOLDERS_PATH = '/kaggle/input/mice-pos-adj-not-random/mice/results/imdb/edits'\nPICKLE_PATH = '/kaggle/input/pickle-imdb-500/imdb_mice.pickle'\nPICKLE_PATH2 = '/kaggle/input/pickle-files-imdb500/imdb_500_adj.pickle'","metadata":{"id":"YBNMiBDDtiW4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\n# utility functions for loading and saving objects\ndef save_pickle(obj, filename):\n    with open(filename,'wb') as f:\n        pickle.dump(obj,f)\n  \ndef load_pickle(filename):\n    with open(filename,'rb') as f:\n        return pickle.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adj = load_pickle(\"/kaggle/input/all-pickle-files/newsgroups_textfooler_ADJ.pickle\")\nnoun = load_pickle(\"/kaggle/input/all-pickle-files/newsgroups_textfooler_NOUN.pickle\")\nverb = load_pickle(\"/kaggle/input/all-pickle-files/newsgroups_textfooler_VERB.pickle\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adj_list = []\nfor item in adj:\n    if len(item) > 1:\n        adj_list.append(item[0][0])\nprint(\"ADJ: \", len(adj_list))\nnoun_list = []\nfor item in noun: \n    if len(item) > 1:\n        noun_list.append(item[0][0])\nprint(\"NOUN: \", len(noun_list))\nverb_list = []\nfor item in verb:\n    if len(item) > 1:\n        verb_list.append(item[0][0])\nprint(\"VERB: \", len(verb_list))\nall_list = adj_list + noun_list + verb_list\nall_set = set(all_list)\nprint(len(all_set))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### IMDb\nMiCE grad: 331/430 sentences flipped \\\nMiCE random: 284/430 sentences flipped \\\nPolyjuice: 391/430 sentences flipped \\\nTextfooler: 153/430 sentences flipped ","metadata":{}},{"cell_type":"markdown","source":"#### Newsgroups\nMiCE grad: 769/1000 sentences flipped \\\nMiCE random: 687/100 \\\nPolyjuice: 630/1000 \\\nTextfooler: 642/1000","metadata":{}},{"cell_type":"markdown","source":"### Evaluation functions","metadata":{}},{"cell_type":"code","source":"def read_edits(path):\n    edits = pd.read_csv(path, sep=\"\\t\", lineterminator=\"\\n\", error_bad_lines=False, warn_bad_lines=True)\n\n    if edits['new_pred'].dtype == pd.np.dtype('float64'):\n        edits['new_pred'] = edits.apply(lambda row: str(int(row['new_pred']) if not np.isnan(row['new_pred']) else \"\"), axis=1)\n        edits['orig_pred'] = edits.apply(lambda row: str(int(row['orig_pred']) if not np.isnan(row['orig_pred']) else \"\"), axis=1)\n        edits['contrast_pred'] = edits.apply(lambda row: str(int(row['contrast_pred']) if not np.isnan(row['contrast_pred']) else \"\"), axis=1)\n    else:\n        edits['new_pred'].fillna(value=\"\", inplace=True)\n        edits['orig_pred'].fillna(value=\"\", inplace=True)\n        edits['contrast_pred'].fillna(value=\"\", inplace=True)\n    return edits\n\ndef get_best_edits(edits):\n    \"\"\" MiCE writes all edits that are found in Stage 2, \n    but we only want to evaluate the smallest per input. \n    Calling get_sorted_e() \"\"\"\n    return edits[edits['sorted_idx'] == 0]","metadata":{"id":"oJ7RUpJ1xHNs","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_edits(edits):\n    temp = edits[edits['sorted_idx'] == 0]\n    minim = temp['minimality'].mean()\n    flipped = temp[temp['new_pred'].astype(str)==temp['contrast_pred'].astype(str)]\n    nunique = temp['data_idx'].nunique()\n    flip_rate = len(flipped)/nunique\n    duration=temp['duration'].mean()\n    metrics = {\n        \"num_total\": nunique,\n        \"num_flipped\": len(flipped),\n        \"flip_rate\": flip_rate,\n        \"minimality\": minim,\n        \"duration\": duration,\n    }\n    for k, v in metrics.items():\n        print(f\"{k}: \\t{round(v, 3)}\")\n    return metrics\n\ndef display_edits(row):\n    html_original, html_edited = html_highlight_diffs(row['orig_editable_seg'], row['edited_editable_seg'])\n    minim = round(row['minimality'], 3)\n    print(f\"MINIMALITY: \\t{minim}\")\n    print(\"\")\n    display(HTML(html_original))\n    display(HTML(html_edited))\n\ndef display_classif_results(rows):\n    for _, row in rows.iterrows():\n      if row['new_contrast_prob_pred']:\n        orig_contrast_prob_pred = round(row['orig_contrast_prob_pred'], 3)\n        new_contrast_prob_pred = round(row['new_contrast_prob_pred'], 3)\n        print(\"-----------------------\")\n        print(f\"ORIG LABEL: \\t{row['orig_pred']}\")\n        print(f\"CONTR LABEL: \\t{row['contrast_pred']} (Orig Pred Prob: {orig_contrast_prob_pred})\")\n        print(f\"NEW LABEL: \\t{row['new_pred']} (New Pred Prob: {new_contrast_prob_pred})\")\n        print(\"\")\n        display_edits(row)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport sys\nsys.path.append(\"..\")\nfrom src.utils import html_highlight_diffs\nfrom IPython.core.display import display, HTML\nimport numpy as np\nfrom src.utils import load_predictor, get_ints_to_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get Flip rates from pickle files","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\npickle_file = \"/kaggle/input/all-pickle-files/newsgroups_mice_gradient.pkl\"\nedit_list = load_pickle(pickle_file)\ntotal = len(edit_list)\nnew_list = []\nfor i in range(1,10):\n    flipped_count = 0\n    for item in edit_list:\n        if len(item) >= i+1:\n            flipped_count+=1\n        # a way to see which of the non-flipped sentences contain the targeted POS tag\n        \"\"\"if len(item) == i:\n            doc = nlp(item[i-1][0])\n            nouns = len([word for word in doc if word.pos_==\"ADJ\"])\n            print(f\"Adjectives: {nouns}\")\"\"\"\n    flip_rate = flipped_count / total\n    print(f\"Flip rate at step {i}: {round(flip_rate*100,3)}%\")\n    print(\"----\"*10)\n    total = flipped_count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## with probs","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n#pickle_file = \"/kaggle/input/all-pickle-files/newsgroups_textfooler_VERB.pickle\"\nimport os \nl = [fil for fil in os.listdir(\"/kaggle/input/all-pickle-files\") if \"beam\" in fil or \"greedy\" in fil]\nfor pickle_file in l:\n    edit_list = load_pickle(\"/kaggle/input/all-pickle-files/\" + pickle_file)\n    new_list = []\n    flip_rate = []\n    total = len(edit_list)\n    for i in range(0,9):\n        flipped_count = 0\n        total = len([item[0] for item in edit_list if len(item)>i])\n        for item in edit_list:\n            if len(item) > i+1:\n                #for newsgroups\n                if (item[i][1] != item[i+1][1]):\n                    flipped_count+=1\n                \"\"\"prev_arr = np.array(item[i][1])\n                prev_max_idx = np.array(prev_arr).argmax()\n                new_arr = np.array(item[i+1][1])\n                new_max_idx = np.array(new_arr).argmax()\n                if new_max_idx!=prev_max_idx:\n                    flipped_count+=1\"\"\"\n                \"\"\"#for imdb\n                if round(item[i][1][0]) != round(item[i+1][1][0]):\n                    flipped_count+=1\"\"\"\n        flip_rate.append(round((flipped_count / total),4))\n        total = flipped_count\n    print(pickle_file.split('/')[-1].split('.pickle')[0].split('.pkl')[0], '=', flip_rate)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create pickle files","metadata":{}},{"cell_type":"markdown","source":"# For text fooler\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ncsv = pd.read_csv(FOLDERS_PATH+\"/log_roberta_imdb_0.csv\")\ncsv.iloc[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\npicklist = []\nedits = pd.read_csv(f\"{FOLDERS_PATH}/mice_imdb_ADJ_0/edits.csv\")\nfor index, row in tqdm(edits.iterrows()):\n  orig_input = row['original_text']\n  orig_pred = predictor.predict(str(orig_input))\n  orig_pred = add_probs(orig_pred)\n  orig_probs = orig_pred['probs'][::-1]\n  my_tupe = [orig_input, orig_probs]\n  picklist.append([my_tupe])\npicklist","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for sublist in tqdm(picklist):\n  text = sublist[0][0]\n  for i in range(10):\n    edits = pd.read_csv(f\"/kaggle/input/textfooler-files/log_allennlp_VERB_new_{i}.csv\")\n    selected_edits = edits.loc[edits[\"original_text\"] == text]\n    #print(text)\n    orig_pred = predictor.predict(text)\n    orig_pred = add_probs(orig_pred)\n    orig_probs = orig_pred['probs'][::-1]\n    #print(orig_probs)\n    if not selected_edits.empty:\n        edited_input = selected_edits.iloc[0][\"perturbed_text\"]\n    else:\n        break\n    if pd.isna(edited_input):\n        break\n    else:\n        if i!=0:\n            sublist.append([text, orig_probs])\n        #display_classif_results(selected_edits)\n        text = str(edited_input)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open('imdb_textfooler_VERB.pickle', 'wb') as handle:\n    pickle.dump(picklist, handle)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# For Mice and Polyjuice","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\npicklist = []\nedits = read_edits(f\"{FOLDERS_PATH}/mice_imdb_VERB_0/edits.csv\")\nedits = get_best_edits(edits)\nfor index, row in tqdm(edits.iterrows()):\n  orig_input = row['orig_input']\n  orig_pred = predictor.predict(str(orig_input))\n  orig_pred = add_probs(orig_pred)\n  orig_probs = orig_pred['probs'][::-1]\n  my_tupe = (orig_input, orig_probs)\n  picklist.append([my_tupe])","metadata":{"id":"F7QdHc_Tt-bm","outputId":"85444bcb-becd-465f-de03-de5a415c5871","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for sublist in tqdm(picklist):\n  text = sublist[0][0]\n  for i in range(10):\n    edits = read_edits(f\"{FOLDERS_PATH}/mice_imdb_VERB_{i}/edits.csv\")\n    edits = get_best_edits(edits) \n    selected_edits = edits.loc[edits[\"orig_input\"] == text]\n    #print(text)\n    orig_pred = predictor.predict(text)\n    orig_pred = add_probs(orig_pred)\n    orig_probs = orig_pred['probs'][::-1]\n    #print(orig_probs)\n    edited_input = selected_edits.iloc[0][\"edited_input\"]\n    \n    if pd.isna(edited_input):\n        break\n    else:\n        if i!=0:\n            sublist.append((text, orig_probs))\n        #display_classif_results(selected_edits)\n        text = str(edited_input)","metadata":{"id":"bHq9FR0qh296","outputId":"b7a063c7-4c4e-4493-f22b-7afe78c5ad1a","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open('imdb_mice_verb.pickle', 'wb') as handle:\n    pickle.dump(picklist, handle)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}