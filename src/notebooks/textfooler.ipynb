{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install allennlp==1.2.2 allennlp_models==1.2.2","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install textattack[tensorflow]","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install overrides==3.1.0 munch==2.5.0 more_itertools==8.4.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torchfile","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"id":"JkcCijQpCtec","outputId":"8dfa03f3-9976-4682-c627-b096052754d9","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone --branch pos_Adj https://github.com/thanoskaravangelis/mice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd mice","metadata":{"execution":{"iopub.status.busy":"2023-05-07T11:21:43.388222Z","iopub.execute_input":"2023-05-07T11:21:43.389307Z","iopub.status.idle":"2023-05-07T11:21:43.404714Z","shell.execute_reply.started":"2023-05-07T11:21:43.389266Z","shell.execute_reply":"2023-05-07T11:21:43.403515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install \"torch>1.7.1\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m spacy download en_core_web_sm","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from allennlp.predictors import Predictor\nimport allennlp_models.classification\nfrom src.predictors.newsgroups.newsgroups_dataset_reader import NewsgroupsDatasetReader\nfrom src.predictors.imdb.imdb_dataset_reader import ImdbDatasetReader\nimport numpy as np\n\nimport textattack\n\nclass AllenNLPModel(textattack.models.wrappers.ModelWrapper):\n    def __init__(self):\n        #for NewsGroups\n        #self.predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/mice-newsgroups-predictor.tar.gz\",\n        #for IMDb\n        self.predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/mice-imdb-predictor.tar.gz\",\n                                             dataset_reader_to_load=ImdbDatasetReader,\n                                            frozen=True)\n        self.model = self.predictor._model\n        self.tokenizer = self.predictor._dataset_reader._tokenizer\n\n    def __call__(self, text_input_list):\n        outputs = []\n        for text_input in text_input_list:\n            outputs.append(self.predictor.predict(sentence=text_input))\n        # For each output, outputs['logits'] contains the logits where\n        # index 0 corresponds to the positive and index 1 corresponds\n        # to the negative score. We reverse the outputs (by reverse slicing,\n        # [::-1]) so that negative comes first and positive comes second.\n        #return [np.exp(output['logits'])/sum(np.exp(output['logits'])) for output in outputs]\n        return [output['logits'][::-1] for output in outputs]\n\nmodel_wrapper = AllenNLPModel()","metadata":{"execution":{"iopub.status.busy":"2023-05-07T11:22:18.467784Z","iopub.execute_input":"2023-05-07T11:22:18.468791Z","iopub.status.idle":"2023-05-07T11:23:36.407597Z","shell.execute_reply.started":"2023-05-07T11:22:18.468752Z","shell.execute_reply":"2023-05-07T11:23:36.406307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(text, special_chars=[\"\\n\", \"\\t\"]):\n    for char in special_chars:\n        text = text.replace(char, \" \")\n    return text","metadata":{"execution":{"iopub.status.busy":"2023-05-07T11:23:36.411807Z","iopub.execute_input":"2023-05-07T11:23:36.412209Z","iopub.status.idle":"2023-05-07T11:23:36.424147Z","shell.execute_reply.started":"2023-05-07T11:23:36.412170Z","shell.execute_reply":"2023-05-07T11:23:36.423193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## For IMDB dataset","metadata":{}},{"cell_type":"code","source":"import os \nfiles_pos = os.listdir(\"/kaggle/input/imdbdata500/imdb_431/pos\")\nfiles_neg = os.listdir(\"/kaggle/input/imdbdata500/imdb_431/neg\")\ndatalist = []\nfor item in files_pos:\n    my_file = open(\"/kaggle/input/imdbdata500/imdb_431/pos/\"+item, \"r\")\n    text = clean_text(my_file.read())\n    my_file.close()\n    datalist.append((text, 1))\n\nfor item in files_neg:\n    my_file = open(\"/kaggle/input/imdbdata500/imdb_431/neg/\"+item, \"r\")\n    text = clean_text(my_file.read())\n    my_file.close()\n    datalist.append((text, 0))","metadata":{"execution":{"iopub.status.busy":"2023-05-07T11:23:36.427158Z","iopub.execute_input":"2023-05-07T11:23:36.427432Z","iopub.status.idle":"2023-05-07T11:23:39.298803Z","shell.execute_reply.started":"2023-05-07T11:23:36.427405Z","shell.execute_reply":"2023-05-07T11:23:39.297699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## For newsgroups","metadata":{}},{"cell_type":"code","source":"d = {\"talk\":3, \"rec\":1, \"sci\":2, \"comp\":0, \"soc\":4, \"alt\":6, \"misc\":5}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os \nfrom src.utils import add_probs, get_ints_to_labels\nimport numpy as np\nfrom tqdm import tqdm\n\nints_to_labels = get_ints_to_labels(model_wrapper.predictor)\n\nfiles_pos = os.listdir(\"/kaggle/input/newsgroups-mice/newsgroups/pos\")\nfiles_neg = os.listdir(\"/kaggle/input/newsgroups-mice/newsgroups/neg\")\ndatalist = []\nfor item in tqdm(files_pos):\n    my_file = open(\"/kaggle/input/newsgroups-mice/newsgroups/pos/\"+item, \"r\")\n    text = clean_text(my_file.read())\n    my_file.close()\n    orig_pred = model_wrapper.predictor.predict(text)\n    orig_pred = add_probs(orig_pred)\n    orig_probs = orig_pred['probs']\n    orig_label = ints_to_labels[np.argmax(orig_probs)]\n    datalist.append((text, d[orig_label]))\n\nfor item in tqdm(files_neg):\n    my_file = open(\"/kaggle/input/newsgroups-mice/newsgroups/neg/\"+item, \"r\")\n    text = clean_text(my_file.read())\n    my_file.close()\n    orig_pred = model_wrapper.predictor.predict(text)\n    orig_pred = add_probs(orig_pred)\n    orig_probs = orig_pred['probs']\n    orig_label = ints_to_labels[np.argmax(orig_probs)]\n    datalist.append((text, d[orig_label]))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open(\"datalist.pickle\",\"wb\") as myf:\n    pickle.dump(datalist, myf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load datalist from pickle","metadata":{}},{"cell_type":"code","source":"import pickle\nwith open(\"datalist.pickle\",\"rb\") as myf:\n    datalist = pickle.load(myf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Remove sentences with zero length and view final length of dataset","metadata":{}},{"cell_type":"code","source":"for it in datalist:\n    if len(it[0]) == 0:\n        print(it)\nlen(datalist)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T11:23:39.301781Z","iopub.execute_input":"2023-05-07T11:23:39.302485Z","iopub.status.idle":"2023-05-07T11:23:39.312911Z","shell.execute_reply.started":"2023-05-07T11:23:39.302442Z","shell.execute_reply":"2023-05-07T11:23:39.311684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datalist.remove(('',1))\nlen(datalist)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T11:23:39.314541Z","iopub.execute_input":"2023-05-07T11:23:39.316083Z","iopub.status.idle":"2023-05-07T11:23:39.323610Z","shell.execute_reply.started":"2023-05-07T11:23:39.316042Z","shell.execute_reply":"2023-05-07T11:23:39.322428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datalist.remove(('                                                           ~~15 ', 0))\nlen(datalist)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Examples of textattack's pretrained models and their usage can be found here: https://github.com/QData/TextAttack/tree/master/textattack/models#readme","metadata":{}},{"cell_type":"code","source":"task = \"allennlp_VERB_news\"\ndataset = textattack.datasets.Dataset(datalist)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T11:23:39.325483Z","iopub.execute_input":"2023-05-07T11:23:39.325925Z","iopub.status.idle":"2023-05-07T11:23:39.332846Z","shell.execute_reply.started":"2023-05-07T11:23:39.325886Z","shell.execute_reply":"2023-05-07T11:23:39.331697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 0","metadata":{}},{"cell_type":"markdown","source":"Create a Part-of-speech tag constrain that allows us to have control over the generated edits by specifying what part-of-speech we want to target for modification.","metadata":{}},{"cell_type":"code","source":"from textattack.constraints.pre_transformation_constraint import PreTransformationConstraint\nimport spacy\n\nclass POSWordsModified(PreTransformationConstraint):\n  def __init__(self, targeted_pos_tag):\n    self.targeted_pos_tag = targeted_pos_tag\n    self.nlp = spacy.load(\"en_core_web_sm\")\n  \n  def _get_modifiable_indices(self, current_text):\n      \"\"\"Returns the word indices in current_text which are able to be\n      modified based on targeted pos tag.\"\"\"\n      \n      doc_c = self.nlp(current_text.text)\n      doc_c_list = current_text.words\n      modifiable = []\n      for word in doc_c:\n        if word.pos_==self.targeted_pos_tag:\n            if str(word) in doc_c_list:\n                modifiable.append(doc_c_list.index(str(word)))\n      return set(modifiable)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T11:23:54.479175Z","iopub.execute_input":"2023-05-07T11:23:54.479585Z","iopub.status.idle":"2023-05-07T11:23:54.487669Z","shell.execute_reply.started":"2023-05-07T11:23:54.479547Z","shell.execute_reply":"2023-05-07T11:23:54.486414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attack = textattack.attack_recipes.TextFoolerJin2019.build(model_wrapper)\npw = POSWordsModified(\"VERB\")\ngf = attack.goal_function\nsm = attack.search_method \ntr = attack.transformation\ncs = attack.constraints\ntr.max_candidates = 250\ncs.insert(0,pw)\n\nattack = textattack.attack.Attack(gf, cs, tr, sm)\n# Attack 20 samples with CSV logging and checkpoint saved every 5 interval\nattack_args = textattack.AttackArgs(num_examples=430, log_to_csv=f\"log_{task}_0.csv\", csv_coloring_style=\"plain\", disable_stdout=False)\nattacker = textattack.Attacker(attack, dataset, attack_args)\nattacker.attack_dataset()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-07T11:24:17.421195Z","iopub.execute_input":"2023-05-07T11:24:17.422121Z","iopub.status.idle":"2023-05-07T15:55:11.949160Z","shell.execute_reply.started":"2023-05-07T11:24:17.422080Z","shell.execute_reply":"2023-05-07T15:55:11.947998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndef create_dataset_from_csv(path_to_csv):\n    csv = pd.read_csv(path_to_csv, sep=\",\")\n    datalist=[]\n    for idx, row in csv.iterrows():\n        if row[\"result_type\"]==\"Successful\":\n            text = row[\"perturbed_text\"]\n            label = row[\"perturbed_output\"]\n            datalist.append((text, label))\n    return datalist","metadata":{"execution":{"iopub.status.busy":"2023-05-07T15:55:11.951472Z","iopub.execute_input":"2023-05-07T15:55:11.952423Z","iopub.status.idle":"2023-05-07T15:55:11.959497Z","shell.execute_reply.started":"2023-05-07T15:55:11.952381Z","shell.execute_reply":"2023-05-07T15:55:11.958088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Steps 1 through 9","metadata":{}},{"cell_type":"code","source":"for num_of_phase in range(1,10):\n    attack = textattack.attack_recipes.TextFoolerJin2019.build(model_wrapper)\n    pw = POSWordsModified(\"VERB\")\n    gf = attack.goal_function\n    sm = attack.search_method \n    tr = attack.transformation\n    cs = attack.constraints\n    tr.max_candidates = 250\n    cs.append(pw)\n\n    attack = textattack.attack.Attack(gf, cs, tr, sm)\n    datalist = create_dataset_from_csv(f\"/kaggle/working/mice/log_{task}_{num_of_phase-1}.csv\")\n    dataset = textattack.datasets.Dataset(datalist)\n    num_to_attack = len(datalist)\n    attack_args = textattack.AttackArgs(num_examples=num_to_attack, log_to_csv=f\"log_{task}_{num_of_phase}.csv\", csv_coloring_style=\"plain\", disable_stdout=True)\n    attacker = textattack.Attacker(attack, dataset, attack_args)\n    attacker.attack_dataset()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-07T15:55:11.961717Z","iopub.execute_input":"2023-05-07T15:55:11.962823Z","iopub.status.idle":"2023-05-07T17:10:47.514416Z","shell.execute_reply.started":"2023-05-07T15:55:11.962779Z","shell.execute_reply":"2023-05-07T17:10:47.513208Z"},"trusted":true},"execution_count":null,"outputs":[]}]}