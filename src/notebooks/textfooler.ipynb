{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Installs"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["!pip install allennlp==1.2.2 allennlp_models==1.2.2"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["!pip install textattack[tensorflow]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install overrides==3.1.0 munch==2.5.0 more_itertools==8.4.0"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install torchfile"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JkcCijQpCtec","outputId":"8dfa03f3-9976-4682-c627-b096052754d9","scrolled":true,"trusted":true},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!git clone --branch pos_Adj https://github.com/thanoskaravangelis/mice"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T11:21:43.389307Z","iopub.status.busy":"2023-05-07T11:21:43.388222Z","iopub.status.idle":"2023-05-07T11:21:43.404714Z","shell.execute_reply":"2023-05-07T11:21:43.403515Z","shell.execute_reply.started":"2023-05-07T11:21:43.389266Z"},"trusted":true},"outputs":[],"source":["%cd mice"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install \"torch>1.7.1\""]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["!python -m spacy download en_core_web_sm"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T11:22:18.468791Z","iopub.status.busy":"2023-05-07T11:22:18.467784Z","iopub.status.idle":"2023-05-07T11:23:36.407597Z","shell.execute_reply":"2023-05-07T11:23:36.406307Z","shell.execute_reply.started":"2023-05-07T11:22:18.468752Z"},"trusted":true},"outputs":[],"source":["from allennlp.predictors import Predictor\n","import allennlp_models.classification\n","from src.predictors.newsgroups.newsgroups_dataset_reader import NewsgroupsDatasetReader\n","from src.predictors.imdb.imdb_dataset_reader import ImdbDatasetReader\n","import numpy as np\n","\n","import textattack\n","\n","class AllenNLPModel(textattack.models.wrappers.ModelWrapper):\n","    def __init__(self):\n","        #for NewsGroups\n","        #self.predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/mice-newsgroups-predictor.tar.gz\",\n","        #for IMDb\n","        self.predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/mice-imdb-predictor.tar.gz\",\n","                                             dataset_reader_to_load=ImdbDatasetReader,\n","                                            frozen=True)\n","        self.model = self.predictor._model\n","        self.tokenizer = self.predictor._dataset_reader._tokenizer\n","\n","    def __call__(self, text_input_list):\n","        outputs = []\n","        for text_input in text_input_list:\n","            outputs.append(self.predictor.predict(sentence=text_input))\n","        # For each output, outputs['logits'] contains the logits where\n","        # index 0 corresponds to the positive and index 1 corresponds\n","        # to the negative score. We reverse the outputs (by reverse slicing,\n","        # [::-1]) so that negative comes first and positive comes second.\n","        #return [np.exp(output['logits'])/sum(np.exp(output['logits'])) for output in outputs]\n","        return [output['logits'][::-1] for output in outputs]\n","\n","model_wrapper = AllenNLPModel()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T11:23:36.412209Z","iopub.status.busy":"2023-05-07T11:23:36.411807Z","iopub.status.idle":"2023-05-07T11:23:36.424147Z","shell.execute_reply":"2023-05-07T11:23:36.423193Z","shell.execute_reply.started":"2023-05-07T11:23:36.412170Z"},"trusted":true},"outputs":[],"source":["def clean_text(text, special_chars=[\"\\n\", \"\\t\"]):\n","    for char in special_chars:\n","        text = text.replace(char, \" \")\n","    return text"]},{"cell_type":"markdown","metadata":{},"source":["## For IMDB dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T11:23:36.427432Z","iopub.status.busy":"2023-05-07T11:23:36.427158Z","iopub.status.idle":"2023-05-07T11:23:39.298803Z","shell.execute_reply":"2023-05-07T11:23:39.297699Z","shell.execute_reply.started":"2023-05-07T11:23:36.427405Z"},"trusted":true},"outputs":[],"source":["import os \n","files_pos = os.listdir(\"/kaggle/input/imdbdata500/imdb_431/pos\")\n","files_neg = os.listdir(\"/kaggle/input/imdbdata500/imdb_431/neg\")\n","datalist = []\n","for item in files_pos:\n","    my_file = open(\"/kaggle/input/imdbdata500/imdb_431/pos/\"+item, \"r\")\n","    text = clean_text(my_file.read())\n","    my_file.close()\n","    datalist.append((text, 1))\n","\n","for item in files_neg:\n","    my_file = open(\"/kaggle/input/imdbdata500/imdb_431/neg/\"+item, \"r\")\n","    text = clean_text(my_file.read())\n","    my_file.close()\n","    datalist.append((text, 0))"]},{"cell_type":"markdown","metadata":{},"source":["## For newsgroups"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["d = {\"talk\":3, \"rec\":1, \"sci\":2, \"comp\":0, \"soc\":4, \"alt\":6, \"misc\":5}"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["import os \n","from src.utils import add_probs, get_ints_to_labels\n","import numpy as np\n","from tqdm import tqdm\n","\n","ints_to_labels = get_ints_to_labels(model_wrapper.predictor)\n","\n","files_pos = os.listdir(\"/kaggle/input/newsgroups-mice/newsgroups/pos\")\n","files_neg = os.listdir(\"/kaggle/input/newsgroups-mice/newsgroups/neg\")\n","datalist = []\n","for item in tqdm(files_pos):\n","    my_file = open(\"/kaggle/input/newsgroups-mice/newsgroups/pos/\"+item, \"r\")\n","    text = clean_text(my_file.read())\n","    my_file.close()\n","    orig_pred = model_wrapper.predictor.predict(text)\n","    orig_pred = add_probs(orig_pred)\n","    orig_probs = orig_pred['probs']\n","    orig_label = ints_to_labels[np.argmax(orig_probs)]\n","    datalist.append((text, d[orig_label]))\n","\n","for item in tqdm(files_neg):\n","    my_file = open(\"/kaggle/input/newsgroups-mice/newsgroups/neg/\"+item, \"r\")\n","    text = clean_text(my_file.read())\n","    my_file.close()\n","    orig_pred = model_wrapper.predictor.predict(text)\n","    orig_pred = add_probs(orig_pred)\n","    orig_probs = orig_pred['probs']\n","    orig_label = ints_to_labels[np.argmax(orig_probs)]\n","    datalist.append((text, d[orig_label]))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pickle\n","with open(\"datalist.pickle\",\"wb\") as myf:\n","    pickle.dump(datalist, myf)"]},{"cell_type":"markdown","metadata":{},"source":["Load datalist from pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pickle\n","with open(\"datalist.pickle\",\"rb\") as myf:\n","    datalist = pickle.load(myf)"]},{"cell_type":"markdown","metadata":{},"source":["Remove sentences with zero length and view final length of dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T11:23:39.302485Z","iopub.status.busy":"2023-05-07T11:23:39.301781Z","iopub.status.idle":"2023-05-07T11:23:39.312911Z","shell.execute_reply":"2023-05-07T11:23:39.311684Z","shell.execute_reply.started":"2023-05-07T11:23:39.302442Z"},"trusted":true},"outputs":[],"source":["for it in datalist:\n","    if len(it[0]) == 0:\n","        print(it)\n","len(datalist)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T11:23:39.316083Z","iopub.status.busy":"2023-05-07T11:23:39.314541Z","iopub.status.idle":"2023-05-07T11:23:39.323610Z","shell.execute_reply":"2023-05-07T11:23:39.322428Z","shell.execute_reply.started":"2023-05-07T11:23:39.316042Z"},"trusted":true},"outputs":[],"source":["datalist.remove(('',1))\n","len(datalist)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["datalist.remove(('                                                           ~~15 ', 0))\n","len(datalist)"]},{"cell_type":"markdown","metadata":{},"source":["Examples of textattack's pretrained models and their usage can be found here: https://github.com/QData/TextAttack/tree/master/textattack/models#readme"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T11:23:39.325925Z","iopub.status.busy":"2023-05-07T11:23:39.325483Z","iopub.status.idle":"2023-05-07T11:23:39.332846Z","shell.execute_reply":"2023-05-07T11:23:39.331697Z","shell.execute_reply.started":"2023-05-07T11:23:39.325886Z"},"trusted":true},"outputs":[],"source":["task = \"allennlp_VERB_news\"\n","dataset = textattack.datasets.Dataset(datalist)"]},{"cell_type":"markdown","metadata":{},"source":["## Step 0"]},{"cell_type":"markdown","metadata":{},"source":["Create a Part-of-speech tag constrain that allows us to have control over the generated edits by specifying what part-of-speech we want to target for modification."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T11:23:54.479585Z","iopub.status.busy":"2023-05-07T11:23:54.479175Z","iopub.status.idle":"2023-05-07T11:23:54.487669Z","shell.execute_reply":"2023-05-07T11:23:54.486414Z","shell.execute_reply.started":"2023-05-07T11:23:54.479547Z"},"trusted":true},"outputs":[],"source":["from textattack.constraints.pre_transformation_constraint import PreTransformationConstraint\n","import spacy\n","\n","class POSWordsModified(PreTransformationConstraint):\n","  def __init__(self, targeted_pos_tag):\n","    self.targeted_pos_tag = targeted_pos_tag\n","    self.nlp = spacy.load(\"en_core_web_sm\")\n","  \n","  def _get_modifiable_indices(self, current_text):\n","      \"\"\"Returns the word indices in current_text which are able to be\n","      modified based on targeted pos tag.\"\"\"\n","      \n","      doc_c = self.nlp(current_text.text)\n","      doc_c_list = current_text.words\n","      modifiable = []\n","      for word in doc_c:\n","        if word.pos_==self.targeted_pos_tag:\n","            if str(word) in doc_c_list:\n","                modifiable.append(doc_c_list.index(str(word)))\n","      return set(modifiable)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T11:24:17.422121Z","iopub.status.busy":"2023-05-07T11:24:17.421195Z","iopub.status.idle":"2023-05-07T15:55:11.949160Z","shell.execute_reply":"2023-05-07T15:55:11.947998Z","shell.execute_reply.started":"2023-05-07T11:24:17.422080Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["attack = textattack.attack_recipes.TextFoolerJin2019.build(model_wrapper)\n","pw = POSWordsModified(\"VERB\")\n","gf = attack.goal_function\n","sm = attack.search_method \n","tr = attack.transformation\n","cs = attack.constraints\n","tr.max_candidates = 250\n","cs.insert(0,pw)\n","\n","attack = textattack.attack.Attack(gf, cs, tr, sm)\n","# Attack 20 samples with CSV logging and checkpoint saved every 5 interval\n","attack_args = textattack.AttackArgs(num_examples=430, log_to_csv=f\"log_{task}_0.csv\", csv_coloring_style=\"plain\", disable_stdout=False)\n","attacker = textattack.Attacker(attack, dataset, attack_args)\n","attacker.attack_dataset()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T15:55:11.952423Z","iopub.status.busy":"2023-05-07T15:55:11.951472Z","iopub.status.idle":"2023-05-07T15:55:11.959497Z","shell.execute_reply":"2023-05-07T15:55:11.958088Z","shell.execute_reply.started":"2023-05-07T15:55:11.952381Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","def create_dataset_from_csv(path_to_csv):\n","    csv = pd.read_csv(path_to_csv, sep=\",\")\n","    datalist=[]\n","    for idx, row in csv.iterrows():\n","        if row[\"result_type\"]==\"Successful\":\n","            text = row[\"perturbed_text\"]\n","            label = row[\"perturbed_output\"]\n","            datalist.append((text, label))\n","    return datalist"]},{"cell_type":"markdown","metadata":{},"source":["## Steps 1 through 9"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T15:55:11.962823Z","iopub.status.busy":"2023-05-07T15:55:11.961717Z","iopub.status.idle":"2023-05-07T17:10:47.514416Z","shell.execute_reply":"2023-05-07T17:10:47.513208Z","shell.execute_reply.started":"2023-05-07T15:55:11.962779Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["for num_of_phase in range(1,10):\n","    attack = textattack.attack_recipes.TextFoolerJin2019.build(model_wrapper)\n","    pw = POSWordsModified(\"VERB\")\n","    gf = attack.goal_function\n","    sm = attack.search_method \n","    tr = attack.transformation\n","    cs = attack.constraints\n","    tr.max_candidates = 250\n","    cs.append(pw)\n","\n","    attack = textattack.attack.Attack(gf, cs, tr, sm)\n","    datalist = create_dataset_from_csv(f\"/kaggle/working/mice/log_{task}_{num_of_phase-1}.csv\")\n","    dataset = textattack.datasets.Dataset(datalist)\n","    num_to_attack = len(datalist)\n","    attack_args = textattack.AttackArgs(num_examples=num_to_attack, log_to_csv=f\"log_{task}_{num_of_phase}.csv\", csv_coloring_style=\"plain\", disable_stdout=True)\n","    attacker = textattack.Attacker(attack, dataset, attack_args)\n","    attacker.attack_dataset()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
